%===================================== CHAPTER 9 Testing =================================
\chapter{Testing}
\label{chap:testing}

The following subsections describe the strategies for the testing levels unit test, integration test, system test, costumer acceptance test and usability test. 
The unit, integration and system tests were done in an iterative manner. After the test suits were performed and the results were documented, the testers mended the issues in the system that appeared during the test. After the mending, the test suit was executed again. This cycle was repeated until there was no issues left in the system and all test cases got the expected result. The issues that were discovered during all the tests are described in every testing level section. 


\section{Unit testing}
\label{sec:unit_testing}
The purpose of unit testing is to ensure that every piece of code that is implemented in the system is functional and correct. It was necessary to prioritize which units should be tested, considering the amount of time given for the project. 
The units in these tests were PHP, Java and JavaScript classes. Therefore it was necessary to use different unit testing tools. Back-end code was tested using PHPUnit framework \cite{KF2}, and JUnit \cite{jUnit} and the extension DbUnit \cite{dbUnit}. The front-end code was tested by using an AngularJS unit testing tool, called Karma \cite{KF3}. 
The classes that were tested are listed under the unit column in \textbf{\Crefrange{Tab:phptesting}{Tab:karmatesting}}. The classes that were left out in the documented tests were tested manually by the developers.

\subsection{Roles and responsibilities}
To get a structured testing experience, the team had to delegate responsibility for the units. The roles correspond with the roles that were given at the start of this project (see \textbf{Section \ref{sec:scrum_team_and_roles}}), so the testers would have good knowledge of the code and know how it works. The delegated responsibilities are presented in \textbf{\Crefrange{Tab:phptesting}{Tab:karmatesting}}.



\begin{table}[H]
	\caption{Shows the delegated responsibilities in testing the back-end part of the system written in PHP code.}
	\label{Tab:phptesting}
	\begin{center}
		\begin{tabular}{ | l | l | l |}
			\hline
			\multicolumn{3}{|c|}{\textbf{PHPUnit testing}} \\
			\hline
			\textbf{Unit ID} & \textbf{Unit} & \textbf{Responsible} \\ \hline
			UN1 & Database Helper & Kjersti \\ \hline
			UN2 & Database Story & Kjersti \\ \hline
			UN3 & Database User & Eivind \\ \hline
			UN4 & User Model & Eivind \\ \hline			
			UN5 & Compute Preference Value & Kjersti \\ \hline			
		\end{tabular}
	\end{center}
\end{table}

\begin{table}[H]
		\caption{Shows the delegated responsibilities for the back-end part of the system written in Java code.}
		\label{Tab:junittesting}
	\begin{center}
		\begin{tabular}{ | l | l | l |}
			\hline
			\multicolumn{3}{|c|}{\textbf{JUnit and DbUnit testing}} \\
			\hline
			\textbf{Unit ID} & \textbf{Unit} & \textbf{Responsible} \\ \hline
			UN6 & Recommendation  & Audun \\ \hline
			UN7 & Database connection with Java & Audun \\\hline			
		\end{tabular}
	\end{center}

\end{table}

\begin{table}[H]
	\caption{Shows the delegated responsibilities for testing the front-end.}
	\label{Tab:karmatesting}
	\begin{center}
		\begin{tabular}{ | l | l | l |}
			\hline
			\multicolumn{3}{|c|}{\textbf{AngularJS Karma testing}} \\
			\hline
			\textbf{Unit ID} & \textbf{Unit} & \textbf{Responsible} \\ \hline
			UN8 & UI Login & Ragnhild \\ \hline
			UN9 & UI Story View & Ragnhild \\ \hline
			UN10 & UI Settings & Roar \\ \hline
		\end{tabular}
	\end{center}

\end{table}


\subsection{Test cases}
The testers created test cases and used these as a guide for performing the tests. Each test case has an ID and describes exactly what the test should do, what input data to use and what is expected to happen when the test is running. An example of a unit test can be found in \textbf{Table \ref{Tab:unittestexample}}. All the unit test cases are presented in \textbf{Appendix \ref{app:unittest}}.

\begin{center}
	\begin{longtable}{ | p{1cm} | p{5.5cm} | p{4cm} | p{4.5cm} | p{2cm}|}
		\caption[Unit test cases]{ Unit test case for updating rating value} \label{Tab:unittestexample}\\
		
		\hline {\bf Test case ID} & {\bf Description} & {\bf Input data} & {\bf Expected results} & {\bf Result}\\ \hline
		
		\multicolumn{5}{| >{\columncolor[gray]{0.8}} c |}{Unit 1: Database Helper}	\\\hline
		
		
		UN1.1 & Update one rating value in the database & Random userId, random storyId, updateValue: 2 & The function should return true when running the database request. & Pass \\\hline
	\end{longtable}
\end{center}
\raggedbottom

\subsection{Detected and mended issues}
This subsection includes some of the most important issues that were discovered during the unit testing, and how they were solved. \newline

In the database communication there were some changes done during the development which made it easier to handle the code. One example was to make the database connection return an array where the array keys matched the column names. This way made it easier to access the different values returned from the database.  
Another issue was discovered with the media format on each story, which was not stored correctly in the database because of an error during the harvesting of the stories from Digitalt fortalt. These types of issues were solves with several checks to see if the information was in the right format or was not null.\newline

During the tests of the first version of the recommender it was running with the time of 11-12 seconds. This was improved by increasing the efficiency of the communication with the database. The recommender was more efficient when the insertion of preference values and recommendations was done with one insert statement to the database instead of respectively 167 and 10 statements. Previously the recommender fetched a whole table from the database with the preference values. Fetching preference values for a specific user instead of all users helped the recommendation module to run faster as well.

\section{Integration testing}
\label{sec:integration_testing}

Integration testing was performed after unit testing, and before system testing. After the back-end and front-end code was tested and integrated, the integration testing could be started, and focused on ensuring that these two modules communicated correctly and that data was moving between them in the right manner. 
Because of the time limitations and the difficulty with learning a new interface to perform integration testing, the developers decided to perform the integration testing with unit testing framework, more particulary with PHPUnit. This testing framework was already known to the developers and therefore easier and less time consuming to use. All the tests were executed by simulating HTTP requests from the UI and checking that the back-end gives the correct response to the specific HTTP request. 



\subsection{Test cases}
The test cases were made by first having a closer look at the different components of the system and the data flows between them (See \textbf{Figure \ref{Fig:architecture}}) 
The integration was performed on the communication between front-end and back-end code, and included test cases made to test all the HTTP request front-end sent to back-end.(About HTTP request in \textbf{Subsection \ref{subsec:frontend-backend_communication}}).
An example of an integration test can be found in \textbf{Table \ref{Tab:integrationtestexample}}. All the integration test cases are described in \textbf{Appendix \ref{Tab:integrationtestcases}}.

\begin{table}
	\centering
	\small
\begin{center}
	\caption{Integration test case for creating a user}
	\label{Tab:integrationtestexample}
	\begin{tabular}{ | p{1cm} | p{5.5cm} | p{4cm} | p{4.5cm} | p{1cm}|}
		\hline
		\textbf{Test case ID} & \textbf{Description} & \textbf{Input data} & \textbf{Expected results} & \textbf{Result} \\ \hline
		
		I.1 & Simulate a HTTP request which will log in a user for the first time with an email adress \newline Call getUserFromEmail to the database & email: 'testnr16@example.com,\newline requestType: addUser & The HTTP request should return successfull message included the newly created userId. The database  function should return a row with the userId, mail, age\textunderscore group, gender and use\textunderscore of\textunderscore location  & Pass \\ \hline
	\end{tabular}
\end{center}
\end{table}

\subsection{Detected and mended issues}

The following paragraph includes some of the most important issues that were discovered during the integration testing, and how they were solved.

The issue that was considered to be the most time consuming one, was to update a user in the database. This issue was detected in the test case I.3. When a user was updated in the UI in the application, the unchanged information that should still be there, was deleted. This was attempted fixed several times with methods that were not adequate. The problem was eventually solved by fetching all information about a user in the database, update the fields in the user model that had been changed, and then insert all the information in the database again. \newline

Other minor issues that were handled were syntax-issues, redundant code that created unnecessary confusion, and missing table attributes in the database.
Changes in the code were made to obtain better structure in the code, such as dividing long code files into smaller ones and to make sure functions return a response if an error occurs. Due to a misunderstanding between front-end and back-end developers, the database returned names of category preference and story categories, and not ID's, this was also mended after the integration testing. 

\section{System testing}
The system testing was performed after the unit tests and integration tests. The test gave the developers a measure of whether the system met all the goals set for the project. The system test included performing a black box test of the system, where the test cases were based on the specified requirements ( See \textbf{Section \ref{subsec:summary_functional_requirements}}) and the use cases (See \textbf{Section \ref{subsec:use_cases}}) defined earlier in this report. \newline

In this test, one of the developers was executing the test. Because it is a black box test, the tester executed the test cases with no access to the code. The tester went through all of the test cases one by one and performed the test cases manually. Due to the time limits of this project, the team was not able to write scripts to perform the test cases. \newline

When the system test was performed, the testers evaluated the test results and then decided if the system as a whole fulfilled all goals for the project. If issues were detected, the developers would mend them and run the tests again. This cycle was repeated until the all the test cases got the expected result. The test should, if done in the expected manner, help the developers of this project to verify and validate if the application meets all the requirements.

\subsection{Test cases}

Each test case has a test identifier and an approach for the tester, and a description of what is intended to happen when the test case is performed. The tester will be referred to as “the user”. 
Some of the test cases have a dependability on other tests. If an issue is detected in one test case, it might cause issues in its dependent test cases. \textbf{Table \ref{Tab:systemtest1}} presents an example of the test cases that were used. The whole system test case document is in \textbf{Appendix \ref{app:systemtest}}. 

\begin{table}[H]
	\centering
	\caption{System test case for creating a recoverable profile.}
	\begin{adjustbox}{center}
	\begin{tabular}[b]{ | l | l  |}
		\hline
		\textbf{Test ID} & T1  \\ \hline
		\textbf{Test Item} & Create recoverable profile \\ \hline&\\[-2ex]
		\textbf{Approach} & \begin{minipage}{5in}The user locate and press the “register user” button in the app. Applies the email in the correct format.. The response is valid and the user gets feedback. \end{minipage}\\ &\\[-2ex]\hline
		\textbf{Input data} &  “newuser@example.com”\\ \hline&\\[-2ex]
		
		\textbf{Expected results} & \begin{minipage}{5in}The user writes the correct email address and get the correct feedback from the system: "Kontakter server" and will be directed to the startup page.\end{minipage}\\ \hline&\\[-2ex]
		
		\textbf{Testing task} & \begin{minipage}{5in}
			\begin{enumerate}[noitemsep]
				\item Click  “create user”-button.
				\item Apply email address to the email input field 
				\item Receive feedback from the system
				\item Check email inbox to se if the correct mail from the system was received 
			\end{enumerate} \end{minipage}
			\\&\\[-2ex] \hline
			\textbf{Depends on tests}& \\ \hline	
			\textbf{Pass/Fail} & Passed \\\hline				
		\end{tabular}
		\end{adjustbox}
		\label{Tab:systemtest1}
	\end{table}
			
			
\subsection{Detected and mended issues}

During the system testing, the testers found repeating recommended stories. This was solved by checking the front-end array and the top ten recommendations and the ratings done by the user for duplicates. \newline

One category icon looked completely different in different views. The reason for this was because this icon had been updated in one part of the code, but not everywhere. This was quickly found and solved. \newline

Sound clips were not working on some Android versions. This was a tough issue which was eventually fixed by using dedicated plug-ins for media, and rewriting the functions for retrieving audio files.\newline

An issue was detected when logging out from a user and then logging in with a different user. The current user would then get the same recommendations as the previous user. The issue was that a user's ID was not cleared properly from the cache when logging out. \newline

Sometimes the recommended stories would take a long time to load. This was fixed by optimizing the harvester. \newline

Can not scroll down if you are scrolling by touching the frame of video, picture and sound- \newline

It was discovered that there was no way to delete the user-made lists. This was easily remedied by adding an "X"-button on these lists to allow deleting them. \newline

When a user created many lists, there was no way to scroll through them. This was remedied by adding a scroll function to the menu. \newline

\section{Customer acceptance test}
\label{sec:acceptance_test}

The customer acceptance test (CAT) was executed during the whole software development life cycle. After a sprint, the customer tested the product, evaluated and gave feedback. In the early stages of the project process this included testing of the prototypes. When working software was delivered to the customer after a sprint, the customer used their own real input data to test the behavior of the system. This kind of testing might reveal a different result than from a regular unit or system testing, when the data could be more realistic since the customer defined it. The customer brought feedback either in meetings or through email. The planned delivery dates are presented in \textbf{Section \ref{sec:milestone_plan}} Project milestone plan.  

\renewcommand{\arraystretch}{2}%
\begin{center}
	\begin{longtable}{ | p{4cm} | p{13cm} | }
		
		\caption[Customer acceptance test - First paper prototype]{Customer acceptance test - First paper prototype} \label{Tab:cattest1}\\
		\hline
		\textbf{Delivery} & First paper prototype\\ \hline
		\textbf{Date} & 20.02.15 \\ \hline 
		\textbf{Comments} &Intuitive interface. The selection of categories is good and fast. Category icon in the listview looks very good.
		\\ \hline
		\textbf{Issues} &
		There should be a description of why the user has to sign in by email, and give the user the option to choose age group and gender. The customer thinks it is easier to click something than to drag an icon from one place to another.  The customer prefers one story per view when the user is browsing recommended stories. The swiping from one story to another should be explained. The customer wants a to-be-rated list and a to-read list. The trash can icon is confusing. It is okay to not prioritize the notifications in the app. 	
		\\ \hline
		
	\end{longtable}
\end{center}

\renewcommand{\arraystretch}{2}%
\begin{center}
	\begin{longtable}{ | p{4cm} | p{13cm} | }
		
		\caption[Customer acceptance test - Second prototype]{Customer acceptance test - Second prototype presented in prototyping tool} \label{Tab:cattest2}\\
		\hline
		\textbf{Delivery} & Second prototype presented in prototyping tool\\ \hline
		\textbf{Date} & 27.02.15 \\ \hline 
		\textbf{Comments}&
		The customer is overall pleased with the prototype, but they have some constructive comments. 
		There are some confusing icons, some lack of consistent terminology, missing introduction for the app, suggestions for different text for buttons and headlines.
		\\ \hline
		\textbf{Issues} 	 &	
		Overlap between not interested and one star rating. Remove the not interested. The author of a story expects that the story is presented the way he/she made it. It would be more correct to have the elements of the story together, in accordance with the authors intention. The elements of every story are now separated with the tabs in the storyview. 	 	
		\\ \hline
		\textbf{Suggestions} &
		 Have a number connected to the rating stars. It is interesting for the customer to know if the user prefers picture, video or sound. The system should log this for every user. It is important to collect the information about the user of the system(age, gender, preferences). It should be discouraged for the user to skip this step. Profile information such as age and gender can not be changed after the specification is once set by the user. Have a little text that appears when you hover over the category icons, or apply a function where you can press a button and reveal the descriptions of the categories. Have the option to share the saved stories on social media. The customer has given this a low priority.
		\\ \hline
	\end{longtable}
\end{center}

\renewcommand{\arraystretch}{2}%
\begin{center}
	\begin{longtable}{ | p{4cm} | p{13cm} | }
		
		\caption[Customer acceptance test - First working software]{Customer acceptance test - First working software } \label{Tab:cattest3}\\
		\hline
		\textbf{Delivery} & First working software\\ \hline
		\textbf{Date} & 17.03.15 \\ \hline
		\textbf{Comments} & The customer likes the user interface of this version and says that it is not necessary to add more functionality, except for the concept view that is not yet implemented. The customer thinks that fetching the stories from Digitalt fortalt is working fast enough.  \\ \hline			
		\textbf{Issues} & 
		Missing a concept description for the application. There are some stories that do not have categories connected to them, these stories should be included in the collaborative filtering.
		\\ \hline		
	\end{longtable}
\end{center}

\renewcommand{\arraystretch}{2}%
\begin{center}
	\begin{longtable}{ | p{4cm} | p{13cm} | }
		
		\caption[Customer acceptance test - Second working software]{Customer acceptance test - Second working software} \label{Tab:cattest4}\\
		\hline
		\textbf{Delivery} & Second working software\\ \hline
		\textbf{Date} & 20.04.15\\ \hline
		\textbf{Comments} & The customer is satisfied with the appearance and structure of the story view. 
		\\ \hline
		\textbf{Issues} & 
		There are only 3 stories in the recommendation view. When you choose interests in the setup of the application, the interests are not marked clearly when you click on them. When choosing a gender in the setup of the application, the selection is not stored in the settings view. The customer discovered that some stories have mismatched icons connected to them. Stories that include a sound clip, do not show this immediately. The sound clip is located inside a tab, and the user would have to click on this to reveal it. Some stories include video clips that are not playing. A user has to sign in every time to visit the app, the user is not remembered. A story that is read is not automatically stored in the ‘Read List’. Uncertain about the cross in the corner of a story in ‘recommended stories view’. The use of this button could mean two things: Either that the user is not interested in this story, or that the user has read this story and just wants to close it for now. The application does not at any time give the user new recommended stories. Missing some kind of feedback when a user has changed the interests in settings. The system should let the user know that it is trying to get new recommended stories based on the new interests. Some stories do not have a picture attached to them. The customer is suggesting a default picture for these stories.
		\\ \hline 	
	\end{longtable}
\end{center}

\renewcommand{\arraystretch}{2}%
\begin{center}
	\begin{longtable}{ | p{4cm} | p{13cm} | }
		
		\caption[Customer acceptance test - Final product]{Customer acceptance test - Final product} \label{Tab:cattest5}\\
		\hline
		\textbf{Delivery} & Final product\\ \hline
		\textbf{Date} & 01.05.15 \\ \hline
		\textbf{Comments} & Customer reported positive feedback and expressed contentment towards the final product.  The last meeting was spent on going through the requirements list found in \textbf{Appendix \ref{app:requirements}} to see if the product met all requirements. There were some comments during the review. 
		R18 is not completed but the customer sees no problem with this and is satisfied with how the system looks now. 
		R22: The information about the app is now hidden and should be moved to a different location in the menu.   \\ \hline
		\textbf{Issues} \\ \hline
	\end{longtable}
\end{center}

\section{Usability testing}

The user testing was performed by the front-end developers. The preliminary work for the user test included doing an analysis of the requirements, and used these as a base for making several test cases. 
A test case included several test steps that the user followed, and the tester observed how the user reacted in every test case. After each test finished there was a discussion with follow-up questions the user had to answer to get a better insight into what was problematic and what was easily understandable.

The user testing was performed over several days where the first test was conducted on the 21st and 22nd of February 2015. This was an early paper prototype while the second session was with the revised prototype on digital devices\cite{protoIO}, this was carried out on Feb. 28th and March 1st. All the tests were performed in accordance with the guidelines and tips provided in \cite{norman2007designing}.

\subsection{Test users}

The test users were asked in advance how much and how many applications they use on handheld devices. They were also asked if and how much reading they see themselves generally doing. The \textbf{Table \ref{Tab:testgroup}} below describes the users that were used as test subjects for the usability testing.  \newline

Low - 1-2 applications/ 1-2 times a day.\newline
Medium - 2-4 applications/ 2-4 times a day.\newline
High - more than 5 applications/ more than 5 times a day.

\begin{table}[H]
	\caption{Test group}
	\label{Tab:testgroup}
	\begin{center}
		\begin{tabular}{ | l | l | l | l |}
			\hline
			\textbf{Gender} & \textbf{Age} & \textbf{Application usage} & \textbf{Other} \\ \hline
			Female & 26 & Medium & Reads some \\\hline
			Male & 32 & High & Does not read much \\\hline
			Female & 51 & Low & Reads a lot \\\hline
			Male & 31 & High & Reads some \\\hline 	
		\end{tabular}
	\end{center}
\end{table}

\subsection{Test cases}

On each test, the user received a set of tasks to complete. These tasks were the following:


\textbf{Create a user} 	
	\begin{enumerate}
		\item Login 
		\item Set personal data 
		\item Add at least 2 categories 
	\end{enumerate}
\textbf{Read a story} 
	\begin{enumerate}
		\item Browse the suggestions 
		\item Add a story to "Les senere" 
		\item Read another story and look at images 
	\end{enumerate}
\textbf{Find and delete }
	\begin{enumerate}
		\item Find the "Les senere" bookmark list
		\item Delete a story from the list
		\item Read another story from the list 
	\end{enumerate}
 \textbf{Change settings}
	\begin{enumerate}
		\item Navigate to settings 
		\item Change preferences 
	\end{enumerate}
	


An example of a usability test results can be found in \textbf{Table \ref{Tab:usabilityTestexample}}. All the usability test cases are described in \textbf{Appendix \ref{app:usabilitytest}}.

\begin{table}[H]
\begin{center}
	\caption{Usability test example }
	\label{Tab:usabilityTestexample}
	\begin{tabular}{ | p{2cm} | p{2cm} | p{13cm}|}	
		\hline
		\textbf{View} & \textbf{Desired next step} & \textbf{Comments}
		\\ \hline
		
		\textbf{6. Recommendations} & 6 & 
		\textbf{Feedback:} The read later button is not understood. Users do not understand that it places the story in a list. Users do not understand that they can swipe in this view, or what they can touch. The users feel a bit "dumped" into this view with no explanation.\newline
		\textbf{Changes:} Remove read later button and add a bookmark icon at the top right instead. Add a card deck or something else to show users that they can swipe. Add a loading animation for when the view is retrieving stories. Change the title of the view to "Anbefalte historier". Make it clear that the card can be touched and make it possible to remove the card.
		\\\hline
	\end{tabular}
\end{center}
\end{table}
	

\subsection{Summary}
The time set aside for each test was about 20 minutes for the test and about 10 minutes for follow-up questions. Observations during the test and the answers provided in the follow-up were implemented in the view feedback and/or the general changes.

To summarize the tests; Each user had his or her own problems with the application but on the whole the user is able to do the task they are asked to complete. So considering the scenarios and use-cases, the application is translating and making the user understand what its functionalities are. There are of course some major inadequate parts, but this is as intended for the test and we are aware of the missing parts.

When it comes to the intuitive understanding, the application has some work to be done. This is covered on a per view basis. And since the user group is not narrow enough we aim to design for everybody and this will act as a constraint for the UI. 

The parts where users are confused are mentioned in the views section.

Paths are on the whole followed by the majority of the testers with some deviation, but this is expected since the prototype is a bit unclear on its formulation on some of the views. But to conclude, the users are almost without issues following the scenarios to the point.

\cleardoublepage